\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{authblk}
\usepackage{apacite}
\usepackage{natbib}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}

\title{Improvements over LVox: an algorithm for estimating forest
  plot's biomass using point clouds}

\author[1]{Félix Chabot}
\author[2]{Richard Fournier}
\author[1]{Toby Dylan Hocking}
\author[2]{Camille Rouet}
\author[2]{Amélie Juckler}
\author[2]{Johannie Lemelin}
\affil[1]{Département de sciences informatiques, Université de Sherbrooke}
\affil[2]{Département de géomatique appliquée, Université de Sherbrooke}

\begin{document}

\maketitle{}

\tableofcontents{}

\section{Introduction}

\subsection{General intro on lidar and how it is generalized in
  forestry}
Light Detection and Ranging (lidar) uses laser technologies to probe
surrounding objects to identity their 3D position and shape. It has
led to major advances to model complex 3D architectures (todo: cite),
civil engineering structures \cite{wang2018} while also being a key
factor for the advancement of autonomous driving
\cite{li2020}. Attaching lidars to various vehicles is common practice
for acquiring data. Aircrafts, for instance, are particularly useful
for surveying large areas. Referred to as airborne laser scanners
(ALS), these lidars are typically used for obtaining very precise
digital terrain models when compared to traditional cameras
\cite{baltsavias1999}. The same can be applied for vegetation modelling
at the canopy level of forests, making those types of scanners really
desirable for foresters.

\subsection{MLS and TLS introduction}

Since ALS are operated at high altitudes, they aren't best suited for
all scenarios of data acquisition. For instance, they can't reliably
capture the fine details of such complex environment because of their
rather low point density per square meter. To work at the scale of the
smaller elements of the forest, it is preferable to use different
types of lidar scanners. Terrestrial laser scanners (TLS), for
instance, offers much finer beams when compared to ALS while providing
a higher point density. They are typically smaller and lighter than
ALS, enough so that a human can carry one. These scanners are
stationary, they shoot beams in a spherical manner at a fixed angular
resolution around the device.

Because TLS are stationary, they can be harder to work with. In order
to get a more complete scan of an area, it is often necessary to scan
the same plot from multiple angles. Since all scans create a new point
cloud, recombining them into a single one can require the use of
strategically placed markers installed during the acquisition, a
time-consuming process. In recent years, we've seen more commercially
available lidars that offer hardware implemented simultaneous
localization and mapping algorithms. Lidars enhanced with this
technology are registering points while keeping track of the
trajectory that the operator took. These devices are known as mobile
laser scanners (MLS). With their mobility, they are inherently able to
capture multiple angles of the same scene. This feature makes data
acquisition much faster than TLS while retaining more fine details
than an ALS would.

\subsection{Lidar limitations}

While all these types of lidar scanners try to solve different
problems with data acquisition, they ultimately all suffer from the
same two glaring issues. The first being occlusion. The light emitted
from these scanners is either in the ultraviolet, visible or near
infrared band. If an object is in the path of a laser beam, the light
will not reach the objects behind it. This is why ALS cannot reliably
reach the understory of a forest and why it's common to use multiple
scans to counteract this effect with TLS. The other issue is beam
divergence. All lidars are affected from the fact that they don't emit
perfect beams, they have a finite precision. This is most apparent
with ALS where the size of the projected beams can reach several
centimeters in diameter. The same effect can be observed with MLS,
where the beams are significantly more imprecise than TLS. This margin
of error induced by the beams causes issues with the resulting point
clouds, because objects further away from the scanner can appear
larger than they truly are.

\subsection{How Lvox deals with these limitations}

To accurately estimate the 3d structure of a forest, it is then
preferable to work with more precise tools such as MLS or TLS, but
it's also necessary to take into account their inherent issues. This
is what the LVox (\cite{nguyen2022}) software seeks to achieve. It
takes as an input point clouds obtained from such devices, and it
outputs estimation of the Plant Area Density (PAD), an indicator of
the amount of vegetation surface inside a volume. The result of LVox
is then a 3D grid of voxels that contains the PAD values and other
metrics. This discretization of space with voxels is necessary because
LVox uses a stochastic approach where the points are seen as
statistical events in 3D space. To account for occlusion, it computes
how many points are contained inside a voxel in comparison to how much
it was explored by rays emitted from a scanner. Reducing the
contribution of highly explored voxels with few points in the PAD
estimation helps with correcting biases induced by the scanners.

\subsection{Lvox objectives}

LVox was developed in \texttt{C++} as a plugin inside the
\textit{Computree} computing platform (\cite{computree}). This
application platform can be used to do various operations on point
clouds, which are mainly aimed at forestry. It is an open-source
software built with the \texttt{QT} (\cite{QT}) framework to offer a
graphical user interface. The interface contains a built-in
visualization window which can be used to display the content of the
point cloud and the various transformation steps that can be applied
on it.

Though \textit{Computree} offers a myriad of advantages for the
researchers who uses it, from an operational standpoint it isn't
ideal. Firstly, the graphical interface, while useful for developing
new process chains for point cloud data, makes reusing an existing
one cumbersome. The user is expected to set the various parameters
directly in the various modal windows before starting the
processing. All these operations can require a lot of manual actions
inside the graphical interface. \texttt{Computree} does offer a
<<batch>> mode that doesn't need to be operated from with a graphical
interface, but it requires a script that was generated with the
interface beforehand.

To lean more on operational use, these issues must be addressed. This
is why we are proposing a new version of LVox which offers better
interoperability by providing an \texttt{R} interface which still uses
\texttt{C++} as the main language for computation. While converting
the existing code into a reusable library, we completely revamped and
simplified the required parameters of the algorithm. We assessed which
ones contribute the most to the PAD estimation and made them use
sensible values by default while still remaining configurable. The
core of the library was also reworked to use parallel processing. This
new change significantly reduced the computation time required. We aim
for this software solution to be easy to install, use and run on
consumer grade hardware while keeping its original open-source
approach.

% \subsection{Leftovers}
% It would not be unusual for operators to analyze close to a hundred
% files. Doing manual operations in the interface for all files would be
% impractical. This why the industry has shown a great interest for
% software solution that offer some sort of pipeline. For instance, one
% of the more widely use tool for processing point cloud data is the
% \texttt{R} package \texttt{lidR} (\cite{roussel2020}). Instead of
% having a graphical interface, this package provides a programming
% interface. Users are expected to write \texttt{R} code that in turn
% will compose their processing pipeline. For handling large amount of
% files, users can simply define the processing for one file and
% leverage the capabilities of the \texttt{R} language to reuse it for a
% collection of files. While \texttt{lidR} is popular for working with
% point clouds, it focuses on ALS data and generic operation on them,
% making it distinct from what LVox aims at doing.

\section{Theoriticals developments used in LVox}

\subsection{Basic elements for LVox; TLS \& MLS geometry, vectors,
  scanner’s position or trajectories}
Several elements must be defined in order to estimate the PAD using
\cite{pimont2019}'s mathematical framework. The input of the system is
point clouds. Point clouds can be thought of as a collection of
cartesian coordinates with associated values. These values vary on the
device used for acquiring the data, we can usually find the intensity
of the return, the point classification, GPS time and many more. These
point clouds are stored in files of varying format. Many laser scanner
manufacturer provides their own proprietary file format, making it
quite difficult to handle them all. The open-source community came up
with a library called \cite{pdal2022} to solve this issue. It can be
used an abstraction layer to load any point cloud files into memory
with the correct representation of the point data. Although many file
formats exist, the American Society for Photogrammetry and Remote
Sensing (ASPRS) standardized the \texttt{las} file format, an open
format which is widely used in the lidar community.

The cartesian coordinates of the points are relative to the scanner's
position. These coordinates can then later be georeferenced so that
they are no longer relative, but rather aligned with a geographic
coordinate system. Altough, when combining multiple point clouds into
one, this often not accurate enough when using high precision
lidars. This is why when acquiring data for multiple scans, operators
are required to use markers made for that specific purpose. These
markers can be spheres made of highly reflective material placed on
tripod that are placed when acquiring the data. Afterwards, as a
post-processing step, it is then possible to correctly align the point
clouds to a specific central coordinate based on the position of the
markers for all these scans. Because of those transformations on the
point clouds, it's then possible for the scanner's position inside the
point cloud to not be centered at the origin of the cartesian
coordinate. Most point cloud file formats don't store the information
on the scanner's position, it's then necessary to keep this
information as metadata for the point cloud of interest in another
place.

However, this issue is only related to TLS. MLS, in counterpart, uses
their internal SLAM algorithm to align all the points to a single
point cloud. The only requirement being that the operator start and
finish their data acquisition at the same location, so that a
technique called <<loop closure>> can be used to account for the point
drift. When using those scanners, the devices then produce two point
clouds, one for the scene and one for the trajectory that the operator
took inside of it.

% Décrire la géométrie de 2 LiDAR utilisés (TLS et MLS): donc pour
% quelques positions avec une diffusion dans un système de coordonnée
% radial, ou avec une diffusion organisée selon des vecteurs
% scanner-objet sur un trajectoire connue.

\subsection{Inclure ici l’importance du RDI}

When seeking to do estimation that accounts for occulusion when using
precise lidars like TLS and MLS, an approach can be to compute the
relative density index (RDI). This was first introduced by
\cite{durrieu2008} where a spherical voxel system was used. The idea
behind this approach is to discretize the space into a grid of voxels
and then look at the individual voxel to see how they were explored by
laser beams emitted from a laser scanner. The number of beams are
categorized into three categories: beams that were intercepted before
the voxel ($N_b$), beams that went through the voxel without being
intercepted ($N_t$) and finally beams that were intercepted inside the
voxel ($N_i$). With each of those beams accounted for a voxel, the
following formula can be used to obtain the RDI for it:
\begin{equation}
RDI = \frac{N_i}{N_i + N_b + N_t}
  \label{eq:rdi}
\end{equation}

Because it accounts for the total number of beams that reached the
voxel in contrast to how many beams were succesful at hitting
vegetation elements, it helps to reduce the contribution of highly
explored voxels with a low number of beams that did hit scene
elements. Invertly, it increases the contribution of highly occluded
voxels with some beams that hit vegetation elements.

Creating a voxel grid from a point cloud is trivial. The first step is
to find the bounding box that will contain all the points. To do that,
the lowest and heighest coordinate value for each dimension needs to
be found by looking at the coordinate value of each point. When
working with multiple point clouds of the same scene, all the points
of all the point clouds are also accounted for to have a compatible
bounds. Once these values are found, a box can be constructed by
combining them appropriately for each dimension. This box can then be
divided equally into increment of a predefined voxel size. For LVox,
this is a parameter that is provided by the user. We decided to use
voxels where each side is of equal lengths, because we found that the
additionnal flexibility did not offer better results, it is also
easier to process the result afterwards.

To compute the different beam categories, the path the beam took must
be recreated virtually from the information that we have from the
point cloud. A laser beams can be thought as an origin point with a
direction. For the purpose of the estimation within the grid, we can
assume that they have a finite range that is entirely contained inside
the bounding box of the scene. The origin point of the beams will
depend on the scanner type. For TLS, it is the position of the device
within the point cloud. In most cases, that is the origin since the
points coordinates are relative the scanner. When working with
multiple scans of the same scene, the relative position of the scanner
inside the aligned point cloud is used instead. This means, each
points in a TLS point cloud has an origin point, which is the position
of the scanner itself. For MLS, since a trajectory is produced as a
by-product of the data acquisiton, it is used as a reference for the
beam's origin. Potentially, every point in those point clouds can have
a different origin along the trajectory. To find the correct one, the
associated gps time for a given point is matched against the
trajectory to find which point inside trajectory's point cloud
corresponds. If no trajectory's point matches for certain point in the
point cloud, a new one is generated by interpolating between the two
closest points. With an origin and a point from a point cloud, it is
then possible to create a vector between those two points that will
serve as the direction of the beam.

Since the beam and voxel count can both be very large, checking every
beam against every voxel for intersections would be greatly
inefficient. Thankfully, there exists highly efficient algorithms that
can find beam's intersections given a uniform grid of voxels, such as
\cite{amanatides1987}. This algorithm will produce a list of all the
explored voxels along a ray with only three floating operations per
intersection. This is, by far, the most computationally intensive part
of the estimation, because this process must be applied for every
point in the point cloud which can be in the hundred of millions. When
producing an intersection, we can also categorize the beam that
produces it. For instance, if the point the beam is reaching is
contained inside the voxel that intersects, it can be categorized as
the $N_i$ value that was presented in the RDI equation
\eqref{eq:rdi}. Likewise, if the point is not contained in the
intersection, we can categorize the beam as $N_t$ if the point is not
yet reached, or as $N_b$ if it was.

% Décrire les fondements du RDI et souligner comment Durrieu et
% al. (2007) on démontré comment ceci débiaise pour les effets de
% l’occlusion

\subsection{Comment on passe du RDI au PAD}
Cadre mathématique de Pimont et al. et de Soma et al.

\subsection{Comment on passe du PAD à la biomasse}
Décrire ici les facteurs de conversion de surface à masse qui
s’appliquent selon l’objet: tige, branche ou feuillage.
\subsection{Dealing with multiple unveiled details: lost rays, ??}
Je ne sais pas si ce paragraphe sera utile, mais j’ai l’impression
qu’il y aura plusieurs éléments fins à décrire pour assurer qu’on a
tous les éléments théoriques en place pour ensuite parler des aspects
algorithmiques de LVox2. Les éléments que j’ai en tête sont :
\begin{itemize}
\item Le choix d’inclure les tirs de toutes les positions du TLS pour
  établir un PAD au lieu de considérer une seule position à la fois.

\item Les considérations de voxels sphériques versus carrés (étude de
  Grau et al., 2015?

\item Utilisation des points d’une scène au lieu de considérer tous
  les points émis (tirs perdus). Ici il faudrait spécifier que l’effet
  de ce choix pourra être évalué à l’aide de LVox2 et des maquettes
  (tree/scene models).

\item Il faudrait regarrder le document initial de Johannie sur LVox1
  où elle mentionne toutes les options disponibles.

\end{itemize}
\section{Implementation of LVox2}

\bibliography{memoire}
\bibliographystyle{apacite}
\end{document}
